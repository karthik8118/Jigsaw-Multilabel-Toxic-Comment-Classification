# Jigsaw-Multilabel-Toxic-Comment-Classification
Our ML algorithm accurately classifies different types of toxicity in user comments, including insults, threats, obscenity, hate speech, and identity-based attacks. It promotes user safety and fosters inclusivity by automatically flagging and categorizing toxic content in online discussions.

# Data can be downloaded from this link : https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data?select=train.csv.zip
